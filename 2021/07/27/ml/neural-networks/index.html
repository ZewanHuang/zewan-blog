

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/zewanblog.ico">
  <link rel="icon" href="/img/zewanblog.ico">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="本文主要介绍神经网络的概念和表述，帮助理解神经网络。">
  <meta name="author" content="Zehuan Huang">
  <meta name="keywords" content="">
  
  <title>神经网络表述 - Zewan 随笔</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.6.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"hN9OTBFN3Qu5oHgDYfEGvoi9-gzGzoHsz","app_key":"QBNI2wT2eJM19a0Lfl90vFhq","server_url":"https://hn9otbfn.lc-cn-n1-shared.com"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Zewan Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/configs/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="神经网络表述">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      Zehuan Huang
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-07-27 12:29" pubdate>
        2021年7月27日 中午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      37
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">神经网络表述</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2021年7月27日 晚上
                
              </p>
            
            <div class="markdown-body">
              <p>在 <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8E%E5%90%B4%E6%81%A9%E8%BE%BE%E3%80%8F/">机器学习『吴恩达』</a> 系列中，无论是线性回归还是逻辑回归，都有一个缺点：当特征太多时，计算的负荷非常大。</p>
<p>而事实上，我们的训练集常常有太多的特征。比如，我们试图训练一个模型来识别视觉对象（比如识别是否为汽车），一种方法是，我们利用图片上一个个像素的值来作为特征，更基础的我们假设只选用灰度图片，这样每个像素只有一个值（而非 RGB 值），且假设采用的都是 $50\times 50$ 像素的小图片，这样就会有 $2500$ 个特征；如果进一步两两特征组合成非线性模型，则大概有 $2500^{2}/2$ 个特征。</p>
<p>普通的逻辑回归模型，不能有效地处理这么多特征，这时候我们需要<strong>神经网络</strong>。</p>
<h2 id="神经元和大脑"><a href="#神经元和大脑" class="headerlink" title="神经元和大脑"></a>神经元和大脑</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>神经网络产生的目的是，人们想尝试设计出模仿大脑的算法。</p>
<p>大脑是十分复杂的，我们能学习数学、编程等多种东西，你可能会想象到，如果想模仿大脑，可能需要写很多不同的算法、软件来模拟所有这些五花八门的学习事件。但能不能假设，大脑做这些事情，不需要过多不同的程序去实现。相反的，<strong>大脑处理事件的方法，只需要一个单一的学习算法就可以。</strong></p>
<p><img src="/img/articles/21-7-27/01.jpg" srcset="/img/loading.gif" lazyload alt="图源于Coursera"></p>
<p>当然，这只是个假设，不过目前还是有一些相关证据的。</p>
<p>神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。结果表明听觉皮层学会了“看”。这类实验称为<strong>神经重接实验</strong>。</p>
<p>从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。</p>
<p>这些只作为前言唠一唠，我们还是主要介绍神经网络的技术细节。</p>
<h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><p>为了构建神经网络模型，首先我们需要思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（<strong>processing unit/Nucleus</strong>），它含有许多输入/树突（<strong>input/Dendrite</strong>），并且有一个输出/轴突（<strong>output/Axon</strong>）。神经网络是大量神经元相互连接并通过电脉冲来交流的一个网络。</p>
<p><img src="/img/articles/21-7-27/02.jpg" srcset="/img/loading.gif" lazyload alt="图源于Coursera"></p>
<p>神经元的作用在于，把自己收到的消息进行计算，并向其它神经元传递消息。比如，想活动一块肌肉，会触发一个神经元向肌肉发送消息，再引起肌肉收缩。我们后面建立的神经网络模型，也是以此为基础的。</p>
<h2 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h2><h3 id="单实例解释"><a href="#单实例解释" class="headerlink" title="单实例解释"></a>单实例解释</h3><p>神经网络模型建立在很多神经元上，每一个神经元又是学习模型。这些神经元（也叫<strong>激活单元</strong>，<strong>activation unit</strong>），采纳一些特征作为输入，并根据自身模型提供输出。</p>
<p>暂且不理会中间的处理，只看输入输出，我们可以简单地了解神经网络：</p>
<p>$$<br>[x_{0}\ x_{1}\ x_{2}\ \cdots]\ \rightarrow \ [\ ]\  \rightarrow \ h_{\theta}(x)<br>$$</p>
<p>以<strong>逻辑回归模型</strong>为神经元示例，设计如下神经网络：</p>
<p><img src="/img/articles/21-7-27/03.png" srcset="/img/loading.gif" lazyload alt="图源于Coursera"></p>
<p>图中的激活单元都是一个逻辑回归模型，其中：</p>
<ul>
<li>输入单元：$x_{1},x_{2},x_{3}$，我们将原始数据输入给它们</li>
<li>中间单元：处理数据，并呈递给下一层</li>
<li>输出单元：计算 $h_{\theta}(x)$</li>
</ul>
<p>神经网络模型是许多逻辑单元按照不同层次组织起来的网络，每一层的输出变量都是下一层的输入变量。如下图，第一层为<strong>输入层</strong> (<strong>Input Layer</strong>)，中间层为<strong>隐藏层</strong> (<strong>Hidden Layers</strong>)，最后一层为<strong>输出层</strong> (<strong>Output Layer</strong>)。另外，我们为每一层增加一个<strong>偏差单元</strong> (<strong>bias unit</strong>)。</p>
<p>偏差单元有点像我们之前在讲述线性回归和逻辑回归时，为满足矩阵运算而添加的单元特征。</p>
<p><img src="/img/articles/21-7-27/04.png" srcset="/img/loading.gif" lazyload></p>
<p>我们用符号来描述模型：</p>
<p>$$<br>\begin{align*}&amp; a_i^{(j)} = \text{“activation” of unit $i$ in layer $j$} \newline&amp; \Theta^{(j)} = \text{matrix of weights controlling function mapping from layer $j$ to layer $j+1$}\end{align*}<br>$$</p>
<p>$a_{i}^{(j)}$ 代表第 $j$ 层的第 $i$ 个激活单元，$\Theta^{(j)}$ 代表从第 $j$ 层到第 $j+1$ 层的权重矩阵（参数矩阵），其尺寸为：以第 $j+1$ 层激活单元数量为行数，以第 $j$ 层激活单元数为列数。例如，上图的神经网络 $\theta^{(1)}$ 为 $3\times 4$ 矩阵。</p>
<p>对于上图的模型，计算表达式为：</p>
<p>$$<br>\begin{align*} a_1^{(2)} &amp;= g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3) \newline a_2^{(2)} &amp;= g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3) \newline a_3^{(2)} &amp;= g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3) \newline h_\Theta(x) &amp;= a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)}) \newline \end{align*}<br>$$</p>
<p>上面的表达仅仅将特征矩阵的一行（一个训练实例）feed 给了神经网络，我们需要将整个训练集都喂给算法进行学习。</p>
<h3 id="向量化表示"><a href="#向量化表示" class="headerlink" title="向量化表示"></a>向量化表示</h3><p>从前面的介绍，我们知道，中间层每一个 $a$ 都是由上一层所有的 $x$ 和每个 $x$ 对应的权重所决定的。我们把这样<strong>从左到右</strong>的算法称为<strong>前向传播算法</strong> (<strong>Forward Propagation</strong>)。</p>
<p>仍然使用上面的例子，先对一个训练实例，将计算过程展开：</p>
<p>首先我们有输入值 $x=[x_{0}\ x_{1}\ x_{2}\ x_{3}]^{T}$，使用 $z^{(2)}=\Theta^{(1)}x,a^{(2)}=g(z^{(2)})$ 计算第二层的值：</p>
<p>$$<br>g(<br>    \left[<br>        \begin{matrix}<br>        \theta_{10}^{(1)} &amp; \theta_{11}^{(1)} &amp; \theta_{12}^{(1)} &amp; \theta_{13}^{(1)}\newline<br>        \theta_{20}^{(1)} &amp; \theta_{21}^{(1)} &amp; \theta_{22}^{(1)} &amp; \theta_{23}^{(1)}\newline<br>        \theta_{30}^{(1)} &amp; \theta_{31}^{(1)} &amp; \theta_{32}^{(1)} &amp; \theta_{33}^{(1)}<br>        \end{matrix}<br>    \right]<br>    \times<br>    \left[<br>        \begin{matrix}<br>        x_{0}\newline<br>        x_{1}\newline<br>        x_{2}\newline<br>        x_{3}\newline<br>        \end{matrix}<br>    \right]<br>)=g(<br>    \left[<br>        \begin{matrix}<br>        \theta_{10}^{(1)}x_{0}+\theta_{11}^{(1)}x_{1}+\theta_{12}^{(1)}x_{2}+\theta_{13}^{(1)}x_{3}\newline<br>        \theta_{20}^{(1)}x_{0}+\theta_{21}^{(1)}x_{1}+\theta_{22}^{(1)}x_{2}+\theta_{23}^{(1)}x_{3}\newline<br>        \theta_{30}^{(1)}x_{0}+\theta_{31}^{(1)}x_{1}+\theta_{32}^{(1)}x_{2}+\theta_{33}^{(1)}x_{3}\newline<br>        \end{matrix}<br>    \right]<br>)=\left[<br>    \begin{matrix}<br>        a_{1}^{(2)}\newline<br>        a_{2}^{(2)}\newline<br>        a_{3}^{(2)}\newline<br>    \end{matrix}<br>\right]<br>$$</p>
<p>计算后给第二层添加 $a_{0}^{(2)}=1$，计算输出的值为：</p>
<p>$$<br>g(<br>    \left[<br>        \begin{matrix}<br>        \theta_{10}^{(2)} &amp; \theta_{11}^{(2)} &amp; \theta_{12}^{(2)} &amp; \theta_{13}^{(2)}<br>        \end{matrix}<br>    \right]<br>    \times<br>    \left[<br>        \begin{matrix}<br>        a_{0}^{(2)} \newline<br>        a_{1}^{(2)} \newline<br>        a_{2}^{(2)} \newline<br>        a_{3}^{(2)} \newline<br>        \end{matrix}<br>    \right]<br>)=g(\theta_{10}^{(2)}a_{0}^{(2)}+\theta_{11}^{(2)}a_{1}^{(2)}+\theta_{12}^{(2)}a_{2}^{(2)}+\theta_{13}^{(2)}a_{3}^{(2)})=h_{\theta}(x)<br>$$</p>
<p>这样我们展示了单个训练实例的计算过程，接下来我们用向量化表示整个训练集的计算。</p>
<p>我们需要对训练集特征矩阵进行转置，使同一个实例的特征都在同一列中。即：</p>
<p>$$<br>a^{(2)} = g(\Theta^{(1)} \times X^{T})<br>$$</p>
<p>事实上中间层可能不止一个，我们可以归纳出计算公式：</p>
<p>$$<br>a^{(j+1)} = g(\Theta^{(j)} \times a^{(j)})<br>$$</p>
<p>从上面的过程我们可以看出，神经网络就像是 logistic regression，只不过把特征值不断地进行计算和变换，从而将原始输入值变为高级的特征值，可以把 $a_{1},a_{2},a_{3}$ 理解成 $x_{0},x_{1},x_{2},x_{3}$ 的进化体。因为过程是梯度下降的，所以中间量 $a$ 变得越来越厉害，所以这些更高级的特征值远比 $x$ 次方更厉害，能更好地预测新数据。<strong>这就是神经网络相比于逻辑回归和线性回归的优势。</strong></p>
<h2 id="应用举例"><a href="#应用举例" class="headerlink" title="应用举例"></a>应用举例</h2><h3 id="实现逻辑运算"><a href="#实现逻辑运算" class="headerlink" title="实现逻辑运算"></a>实现逻辑运算</h3><p>接下来，我们构建神经网络，来实现基础的逻辑运算，包括逻辑与、或、非。</p>
<p>我们可以用这样的一个神经网络来表示 <strong>AND</strong> 函数：</p>
<p><img src="/img/articles/21-7-27/05.png" srcset="/img/loading.gif" lazyload alt="图源于Coursera"></p>
<p>其中权重为 $[-30\ 20\ 20]$，即 $\theta_{0}=-30,\theta_{1}=20,\theta_{2}=20$，则输出函数为 $h_{\Theta}(x)=g(-30+20x_{1}+20x_{2})$</p>
<p>而我们知道 $g(x)$ 的图像是：</p>
<p><img src="/img/articles/21-7-27/06.png" srcset="/img/loading.gif" lazyload alt="图源于Coursera"></p>
<p>这样我们赋值 $x_{1},x_{2}\in \{0,1\}$，得到：</p>
<p>$$<br>\begin{align*}&amp; x_1 = 0 \ \ and \ \ x_2 = 0 \ \ then \ \ g(-30) \approx 0 \newline &amp; x_1 = 0 \ \ and \ \ x_2 = 1 \ \ then \ \ g(-10) \approx 0 \newline &amp; x_1 = 1 \ \ and \ \ x_2 = 0 \ \ then \ \ g(-10) \approx 0 \newline &amp; x_1 = 1 \ \ and \ \ x_2 = 1 \ \ then \ \ g(10) \approx 1\end{align*}<br>$$</p>
<p>这样，我们有 $h_{\Theta}(x)=x_{1} \text{AND} x_{2}$</p>
<p>从上面逻辑与神经网络的构建过程，我们可以看到，我们只需搭建一个无隐藏层的神经网络即可实现，只需在权重上合理分配，即可达到效果。后面将直接给出其它两个逻辑运算的神经网络。</p>
<ul>
<li><strong>逻辑与 AND</strong>：权重为 $-30,20,20$</li>
<li><strong>逻辑或 OR</strong>：权重为 $-10,20,20$</li>
<li><strong>逻辑非 NOT</strong>：权重为 $10,-20$</li>
</ul>
<p><img src="/img/articles/21-7-27/07.png" srcset="/img/loading.gif" lazyload alt="AND &amp; OR &amp; NOT"></p>
<p>我们还可以将神经元组合成更复杂的神经网络，以实现更复杂的运算。例如实现 <strong>XNOR</strong> 功能，要求当且仅当输入的两个值相等时输出 1，反之则输出 0，即</p>
<p>$$<br>\text{XNOR} = (x_{1}\ \text{AND}\ x_{2})\ \text{OR}\ ((\text{NOT}\ x_{1})\ \text{AND}\ (\text{NOT} \ x_{2}))<br>$$</p>
<p><img src="/img/articles/21-7-27/08.png" srcset="/img/loading.gif" lazyload alt="XNOR"></p>
<p>这样我们就得到了一个能实现 <strong>XNOR</strong> 运算符的神经网络。我们来检验一下。</p>
<table>
<thead>
<tr>
<th align="center">$x_{1}$</th>
<th align="center">$x_{2}$</th>
<th align="center">$a_{1}^{(2)}$</th>
<th align="center">$a_{2}^{(2)}$</th>
<th align="center">$h_{\Theta}(x)$</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$0$</td>
<td align="center">$0$</td>
<td align="center">$0$</td>
<td align="center">$1$</td>
<td align="center">$1$</td>
</tr>
<tr>
<td align="center">$0$</td>
<td align="center">$1$</td>
<td align="center">$0$</td>
<td align="center">$0$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">$1$</td>
<td align="center">$0$</td>
<td align="center">$0$</td>
<td align="center">$0$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">$1$</td>
<td align="center">$1$</td>
<td align="center">$1$</td>
<td align="center">$0$</td>
<td align="center">$1$</td>
</tr>
</tbody></table>
<p>按这种组合神经元的方法，我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征，这正是神经网络的优势。</p>
<h3 id="多类别分类"><a href="#多类别分类" class="headerlink" title="多类别分类"></a>多类别分类</h3><p>前面我们介绍过逻辑回归解决多类别分类问题的方法，神经网络同样能实现。</p>
<p>如果我们要训练一个神经网络来识别路人、汽车、摩托车和卡车，在输出层我们应有 4 个值，分别对应以上四种类别。</p>
<p><img src="/img/articles/21-7-27/09.png" srcset="/img/loading.gif" lazyload alt="图源于Coursera"></p>
<p>我们定义结果如下，对应路人、汽车、摩托车和卡车：</p>
<p>$$<br>y^{(i)}=<br>\left[<br>\begin{matrix}<br>1\newline 0\newline 0\newline 0<br>\end{matrix}<br>\right],<br>\left[<br>\begin{matrix}<br>0\newline 1\newline 0\newline 0<br>\end{matrix}<br>\right],<br>\left[<br>\begin{matrix}<br>0\newline 0\newline 1\newline 0<br>\end{matrix}<br>\right],<br>\left[<br>\begin{matrix}<br>0\newline 0\newline 0\newline 1<br>\end{matrix}<br>\right]<br>$$</p>
<p>这样我们构建出来的神经网络大概如下：</p>
<p>$$<br>\left[\begin{matrix}x_{0}\newline x_{1}\newline x_{2}\newline \cdots\newline x_{n}\end{matrix}\right]<br>\rightarrow<br>\left[\begin{matrix}a_{0}^{(2)}\newline a_{1}^{(2)}\newline a_{2}^{(2)}\newline \cdots \end{matrix}\right]<br>\rightarrow<br>\left[\begin{matrix}a_{0}^{(3)}\newline a_{1}^{(3)}\newline a_{2}^{(3)}\newline \cdots \end{matrix}\right]<br>\rightarrow \cdots\rightarrow<br>\left[\begin{matrix}h_{\Theta}(x)_{1}\newline h_{\Theta}(x)_{2}\newline h_{\Theta}(x)_{3}\newline h_{\Theta}(x)_{4}\newline\end{matrix}\right]<br>$$</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文从大脑和神经元的人体结构引入，介绍了神经网络的结构，由输入层、隐藏层、输出层组成。同时我们以逻辑回归模型建立激活单元，表示出神经网络，并给出计算公式：$a^{(j+1)} = g(\Theta^{(j)} \times a^{(j)})$</p>
<p>最后我们构造神经网络模型，建立了逻辑运算和多类别分类的模型。当然，本文并没有给出参数求解的细节，而是给出神经网络的表述，帮助理解神经网络的结构和概念。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.coursera.org/learn/machine-learning">[1] 吴恩达 Andrew Ng 机器学习课程</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes">[2] 黄海广博士的机器学习笔记</a></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8E%E5%90%B4%E6%81%A9%E8%BE%BE%E3%80%8F/">机器学习『吴恩达』</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                    
                      <a class="hover-with-bg" href="/tags/ML/">ML</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/07/26/ml/overfit/">
                        <span class="hidden-mobile">过拟合与正则化</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"hN9OTBFN3Qu5oHgDYfEGvoi9-gzGzoHsz","appKey":"QBNI2wT2eJM19a0Lfl90vFhq","placeholder":"说点什么","path":"window.location.pathname","avatar":"retro","meta":["nick","mail","link"],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"https://hn9otbfn.lc-cn-n1-shared.com","emojiCDN":null,"emojiMaps":null,"enableQQ":true,"requiredFields":[],"appid":"hN9OTBFN3Qu5oHgDYfEGvoi9-gzGzoHsz","appkey":"QBNI2wT2eJM19a0Lfl90vFhq"},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        粤ICP备2021021248号
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.2/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-svg.js" ></script>

  





  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
